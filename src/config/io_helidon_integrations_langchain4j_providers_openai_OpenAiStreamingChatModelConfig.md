Type:
[io.helidon.integrations.langchain4j.providers.openai.OpenAiStreamingChatModelConfig](https://helidon.io/docs/v4/apidocs/io.helidon.integrations.langchain4j.providers.openai/io/helidon/integrations/langchain4j/providers/openai/OpenAiStreamingChatModelConfig.html)

This is a standalone configuration type, prefix from configuration root:
`langchain4j.open-ai.streaming-chat-model`

# Configuration options

| key | type | default value | description |
|----|----|----|----|
| `api-key` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.apiKey(java.lang.String) |
| `base-url` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.baseUrl(java.lang.String) |
| `custom-headers` | Map\<string, string\> |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.customHeaders(java.util.Map) |
| `default-request-parameters` | ChatRequestParameters |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.defaultRequestParameters(dev.langchain4j.model.chat.request.ChatRequestParameters) |
| `enabled` | boolean |  | If set to `false` (default), OpenAiStreamingChatModel will not be available even if configured. |
| `frequency-penalty` | double |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.frequencyPenalty(java.lang.Double) |
| `http-client-builder` | HttpClientBuilder |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.httpClientBuilder(dev.langchain4j.http.client.HttpClientBuilder) |
| `listeners` | ChatModelListener\[\] |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.listeners(java.util.List) |
| `log-requests` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.logRequests(java.lang.Boolean) |
| `log-responses` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.logResponses(java.lang.Boolean) |
| `logger` | Logger |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.logger(org.slf4j.Logger) |
| `logit-bias` | Map\<string, int\> |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.logitBias(java.util.Map) |
| `max-completion-tokens` | int |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.maxCompletionTokens(java.lang.Integer) |
| `max-tokens` | int |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.maxTokens(java.lang.Integer) |
| `metadata` | Map\<string, string\> |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.metadata(java.util.Map) |
| `model-name` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.modelName(java.lang.String) |
| `organization-id` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.organizationId(java.lang.String) |
| `parallel-tool-calls` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.parallelToolCalls(java.lang.Boolean) |
| `presence-penalty` | double |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.presencePenalty(java.lang.Double) |
| `project-id` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.projectId(java.lang.String) |
| `return-thinking` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.returnThinking(java.lang.Boolean) |
| `seed` | int |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.seed(java.lang.Integer) |
| `service-tier` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.serviceTier(java.lang.String) |
| `stop` | string\[\] |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.stop(java.util.List) |
| `store` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.store(java.lang.Boolean) |
| `strict-json-schema` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.strictJsonSchema(java.lang.Boolean) |
| `strict-tools` | boolean |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.strictTools(java.lang.Boolean) |
| `temperature` | double |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.temperature(java.lang.Double) |
| `timeout` | Duration |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.timeout(java.time.Duration) |
| `top-p` | double |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.topP(java.lang.Double) |
| `user` | string |  | Generated from dev.langchain4j.model.openai.OpenAiStreamingChatModel.OpenAiStreamingChatModelBuilder.user(java.lang.String) |

Optional configuration options
